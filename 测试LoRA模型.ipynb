{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb1da4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"./data/\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed045fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.5.7: Fast Qwen2_5_Vl patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.546 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastVisionModel\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    model_name=\"lora_model\", # 训练的模型\n",
    "    load_in_4bit=True,  # 如果设置成False对应的是16bit LoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127e0e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The panoramic radiograph revealed diffuse periapical radiolucencies with mixed calcified contents involving multiple teeth (arrows). The periapical lesions extended to the root apices of 45 and 46 (top arrow), and of the left maxillary canine (left middle arrow), right mandibular first molar (middle arrow) and lateral incisor (right middle arrow). Additionally, it exhibited a periodontal radiolucency around the tooth 28.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "FastVisionModel.for_inference(model)\n",
    "\n",
    "image = dataset[0][\"image\"]\n",
    "instruction = \"你是一名专业的放射科医生。请准确描述你在图片中看到的内容。\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\", \"content\":[\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": instruction}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# add_generation_prompt 设置为True相当于是添加 assistant 信息\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False, # 前面已经是应用了apply_chat_template()已经添加了这些特殊符号\n",
    "    return_tensors = 'pt',\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt=True) # skip_prompt设置为True就是返回结果不包括输入的提示词\n",
    "# min_p 设置了一个最低值，只有达到这个值的token才会被考虑。这个值会根据最高概率token的置信度而变化。\n",
    "# 如果设置为0.1，那意味着它只会允许概率至少是最大概率token的1/10，如果设置为0.05，则会允许至少是最大概率token的1/20的token。\n",
    "# temperature 温度是一个用于控制AI生成文本的创造力/多样性水平的参数。\n",
    "# 每一个时刻输出的tokens可选项会有一个概率分布，温度越高，创造力就变低\n",
    "_ = model.generate(**inputs, streamer=text_streamer, max_new_tokens=128, use_cache=True, temperature=1.5, min_p=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
